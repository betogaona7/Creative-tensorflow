{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10 Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/betogaona7/Creative-tensorflow/blob/master/CIFAR_10_Classifier.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ileldQGnCcdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZD5vhNYNE37X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "from tqdm import tqdm\n",
        "import tarfile\n",
        "\n",
        "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
        "\n",
        "# Use Floyd's cifar-10 dataset if present\n",
        "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
        "if isfile(floyd_cifar10_location):\n",
        "    tar_gz_path = floyd_cifar10_location\n",
        "else:\n",
        "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
        "\n",
        "class DLProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "if not isfile(tar_gz_path):\n",
        "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
        "        urlretrieve(\n",
        "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
        "            tar_gz_path,\n",
        "            pbar.hook)\n",
        "\n",
        "if not isdir(cifar10_dataset_folder_path):\n",
        "    with tarfile.open(tar_gz_path) as tar:\n",
        "        tar.extractall()\n",
        "        tar.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DJYlzhpjQGbv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdna5bGjEaIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3d0dfc2-46ae-498e-dbd1-7285df9b8848"
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-j2PDsvIRyev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "1ec02bb3-fcfa-4794-a524-4b2a7186b66f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.os.listdir()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datalab',\n",
              " '.config',\n",
              " '.local',\n",
              " '.keras',\n",
              " '.ipython',\n",
              " 'cifar-10-python.tar.gz',\n",
              " '.cache',\n",
              " 'cifar-10-batches-py',\n",
              " '.nv',\n",
              " '.forever']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "oZqtbCBECceN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Auxiliar functions**"
      ]
    },
    {
      "metadata": {
        "id": "aGTGzKveCceT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def _load_label_names():\n",
        "    \"\"\"\n",
        "    Load the label names from file\n",
        "    \"\"\"\n",
        "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "def load_cfar10_batch(cifar10_folder_path, batch_id):\n",
        "    \"\"\"\n",
        "    Load a batch of the dataset\n",
        "    \"\"\"\n",
        "    with open(cifar10_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
        "        batch = pickle.load(file, encoding='latin1')\n",
        "        \n",
        "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    labels = batch['labels']\n",
        "    \n",
        "    return features, labels\n",
        "\n",
        "def display_stats(cifar10_folder_path, batch_id, sample_id):\n",
        "    \"\"\"\n",
        "    Display stats of the dataset\n",
        "    \"\"\"\n",
        "    batchs_ids = list(range(1,6))\n",
        "    if batch_id not in batchs_ids:\n",
        "        print('Batch id out of range (1 to 5 only)')\n",
        "        return None\n",
        "    \n",
        "    features, labels = load_cfar10_batch(cifar10_folder_path, batch_id)\n",
        "    \n",
        "    if not (0 <= sample_id < len(features)):\n",
        "        print('Sample id out of range (there are only {} saimples in batch {})'.format(len(features), batch_id))\n",
        "        return None\n",
        "    \n",
        "    print('\\nStats of batch: {}'.format(batch_id))\n",
        "    print('Samples: {}'.format(len(features)))\n",
        "    print('Label counts: {}'.format(dict(zip(*np.unique(labels, return_counts=True)))))\n",
        "    print('First 20 labels: {}'.format(labels[:20]))\n",
        "    \n",
        "    sample_image = features[sample_id]\n",
        "    sample_label = labels[sample_id]\n",
        "    label_names =_load_label_names()\n",
        "    \n",
        "    print('\\nExample of Image {}:'.format(sample_id))\n",
        "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
        "    print('Image - Shape: {}'.format(sample_image.shape))\n",
        "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
        "    \n",
        "    plt.axis('off')\n",
        "    plt.imshow(sample_image)\n",
        "    \n",
        "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
        "    \"\"\"\n",
        "    Preprocess data and save it to file\n",
        "    \"\"\"\n",
        "    features = normalize(features)\n",
        "    labels = one_hot_encode(labels)\n",
        "\n",
        "    pickle.dump((features, labels), open(filename, 'wb'))\n",
        "\n",
        "\n",
        "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
        "    \"\"\"\n",
        "    Preprocess Training and Validation Data\n",
        "    \"\"\"\n",
        "    n_batches = 5\n",
        "    valid_features = []\n",
        "    valid_labels = []\n",
        "\n",
        "    for batch_i in range(1, n_batches + 1):\n",
        "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
        "        validation_count = int(len(features) * 0.1)\n",
        "\n",
        "        # Prprocess and save a batch of training data\n",
        "        _preprocess_and_save(\n",
        "            normalize,\n",
        "            one_hot_encode,\n",
        "            features[:-validation_count],\n",
        "            labels[:-validation_count],\n",
        "            'preprocess_batch_' + str(batch_i) + '.p')\n",
        "\n",
        "        # Use a portion of training batch for validation\n",
        "        valid_features.extend(features[-validation_count:])\n",
        "        valid_labels.extend(labels[-validation_count:])\n",
        "\n",
        "    # Preprocess and Save all validation data\n",
        "    _preprocess_and_save(\n",
        "        normalize,\n",
        "        one_hot_encode,\n",
        "        np.array(valid_features),\n",
        "        np.array(valid_labels),\n",
        "        'preprocess_validation.p')\n",
        "\n",
        "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
        "        batch = pickle.load(file, encoding='latin1')\n",
        "\n",
        "    # load the test data\n",
        "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    test_labels = batch['labels']\n",
        "\n",
        "    # Preprocess and Save all test data\n",
        "    _preprocess_and_save(\n",
        "        normalize,\n",
        "        one_hot_encode,\n",
        "        np.array(test_features),\n",
        "        np.array(test_labels),\n",
        "        'preprocess_test.p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oSjBYu3HCceo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Explore the data**"
      ]
    },
    {
      "metadata": {
        "id": "lz_gRevgCcet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "f950f4ac-6754-4849-a808-ecaf66dfee22"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline \n",
        "%config InLineBackend.figure_format = 'retina'\n",
        "\n",
        "cifar10_folder_path = 'cifar-10-batches-py'\n",
        "batch_id = 5\n",
        "sample_id = 1000\n",
        "\n",
        "display_stats(cifar10_folder_path, batch_id, sample_id)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Stats of batch: 5\n",
            "Samples: 10000\n",
            "Label counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
            "First 20 labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
            "\n",
            "Example of Image 1000:\n",
            "Image - Min Value: 28 Max Value: 228\n",
            "Image - Shape: (32, 32, 3)\n",
            "Label - Label Id: 7 Name: horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnRADUOiEGOC/AHT0KujJ34aNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9880913b00>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OVK1JbQ1CcfJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Implement preprocessing functions**"
      ]
    },
    {
      "metadata": {
        "id": "FluP6tokCcfN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    \"\"\" \n",
        "    Normalize a list of sample image data in the range of 0 to 1.\n",
        "        x : List of image data. Image shape is (32, 32, 3)\n",
        "        return: Numpy array of normalized data\n",
        "    \"\"\"\n",
        "    return np.array((x)/255)\n",
        "\n",
        "def one_hot_encode(x):\n",
        "    \"\"\"\n",
        "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
        "        x : List of sample labels\n",
        "        return: Numpy array of one-hot encoded labels\n",
        "    \"\"\"\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(x)\n",
        "    lb.classes_ = [0,1,2,3,4,5,6,7,8,9]\n",
        "    return lb.transform(x)\n",
        "\n",
        "preprocess_and_save_data(cifar10_folder_path, normalize, one_hot_encode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJ59pLCyCcfb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Check point**"
      ]
    },
    {
      "metadata": {
        "id": "FLjqnglMCcff",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yt8cR67aCcfx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Build the network**"
      ]
    },
    {
      "metadata": {
        "id": "DtDmbeweCcf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input\n",
        "def nn_image_input(image_shape):\n",
        "    return tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
        "\n",
        "def nn_label_input(n_classes):\n",
        "    return tf.placeholder(tf.float32, shape=[None, n_classes], name='y')\n",
        "\n",
        "def nn_keep_prob_input():\n",
        "    return tf.placeholder(tf.float32, name='keep_prob')\n",
        "\n",
        "# Convolution and Max pooling \n",
        "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
        "    weights = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]), conv_num_outputs]))\n",
        "    bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
        "    # Apply convolution\n",
        "    x_tensor = tf.nn.conv2d(x_tensor, weights, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
        "    # Add bias \n",
        "    x_tensor = tf.nn.bias_add(x_tensor, bias)\n",
        "    # Add non-linear function\n",
        "    x_tensor = tf.nn.relu(x_tensor)\n",
        "    # Apply max pooling\n",
        "    x_tensor = tf.nn.max_pool(x_tensor, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0],\n",
        "                              pool_strides[1],1], padding='SAME')\n",
        "    return x_tensor\n",
        "\n",
        "# Flatten \n",
        "def flatten(x_tensor):\n",
        "    image_dimensions = x_tensor.get_shape().as_list()\n",
        "    image_flat_size = image_dimensions[1] * image_dimensions[2] * image_dimensions[3]\n",
        "    return tf.reshape(x_tensor, [-1, image_flat_size])\n",
        "\n",
        "# Fully connected layer \n",
        "def fully_conn(x_tensor, num_outputs):\n",
        "    weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), num_outputs], mean=0., stddev=0.1))\n",
        "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
        "    # Apply a fully connected layer\n",
        "    x_tensor = tf.add(tf.matmul(x_tensor, weights), bias)\n",
        "    # Add non-linear function\n",
        "    x_tensor = tf.nn.relu(x_tensor)\n",
        "    return x_tensor\n",
        "\n",
        "# Output layer \n",
        "def output (x_tensor, num_outputs):\n",
        "    weights = tf.Variable(tf.truncated_normal([int(x_tensor.shape[-1]), num_outputs], mean=0., stddev=0.1))\n",
        "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
        "    # Output layer\n",
        "    x_tensor = tf.add(tf.matmul(x_tensor, weights), bias)\n",
        "    return x_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xgw8cPnBCcgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_net(x, keep_prob):\n",
        "    conv_ksize = (4, 4)\n",
        "    conv_strides = (2, 2)\n",
        "    pool_ksize = (4,4)\n",
        "    pool_strides = (2, 2)\n",
        "    \n",
        "    #conv1 = conv2d_maxpool(x, 16, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
        "    #conv2 = conv2d_maxpool(conv1, 8, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
        "    conv2 = conv2d_maxpool(x, 16, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
        "    \n",
        "    fc1 = flatten(conv2)\n",
        "    fc1 = fully_conn(fc1, 256)\n",
        "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
        "    \n",
        "    #fc2 = fully_conn(fc1, 256)\n",
        "    #fc2 = tf.nn.dropout(fc2, keep_prob)\n",
        "    \n",
        "    out = output(fc1, 10)\n",
        "    return out\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5bzpI4XCcgb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train neural network"
      ]
    },
    {
      "metadata": {
        "id": "7cqxzFKUCcgg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_features_labels(features, labels, batch_size):\n",
        "    \"\"\"\n",
        "    Split features and labels into batches\n",
        "    \"\"\"\n",
        "    for start in range(0, len(features), batch_size):\n",
        "        end = min(start + batch_size, len(features))\n",
        "        yield features[start:end], labels[start:end]\n",
        "\n",
        "\n",
        "def load_preprocess_training_batch(batch_id, batch_size):\n",
        "    \"\"\"\n",
        "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
        "    \"\"\"\n",
        "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
        "    features, labels = pickle.load(open(filename, mode='rb'))\n",
        "\n",
        "    # Return the training data in batches of size <batch_size> or less\n",
        "    return batch_features_labels(features, labels, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pWhbU2RMCcg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1771
        },
        "outputId": "ee03d45a-fb0b-4456-99ca-e886440b3ac7"
      },
      "cell_type": "code",
      "source": [
        "def train_neural_network(session, optimizer, keep_proba, feature_batch, label_batch):\n",
        "    return session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_proba})\n",
        "\n",
        "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
        "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
        "    valid_acc = sess.run(accuracy, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.})\n",
        "    print(\"Loss: {:>10.4f} Validation accuracy: {:.6f}\".format(loss, valid_acc))\n",
        "    return None\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "keep_proba = 0.5\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "x = nn_image_input((32, 32, 3))\n",
        "y = nn_label_input(10)\n",
        "keep_prob = nn_keep_prob_input()\n",
        "\n",
        "logits = conv_net(x, keep_prob)\n",
        "logits = tf.identity(logits, name='logits')\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
        "\n",
        "print(\"Checking the training on a single batch\")\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for epoch in range(epochs):\n",
        "        batch_i = 1\n",
        "        for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
        "            train_neural_network(sess, optimizer, keep_proba, batch_features, batch_labels)\n",
        "        print('Epoch {:>2}, CIFAR-10 Batch {}: '.format(epoch+1, batch_i), end='')\n",
        "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the training on a single batch\n",
            "Epoch  1, CIFAR-10 Batch 1: Loss:     2.1016 Validation accuracy: 0.264800\n",
            "Epoch  2, CIFAR-10 Batch 1: Loss:     1.9780 Validation accuracy: 0.335800\n",
            "Epoch  3, CIFAR-10 Batch 1: Loss:     1.9782 Validation accuracy: 0.384200\n",
            "Epoch  4, CIFAR-10 Batch 1: Loss:     1.9111 Validation accuracy: 0.387600\n",
            "Epoch  5, CIFAR-10 Batch 1: Loss:     1.8275 Validation accuracy: 0.414200\n",
            "Epoch  6, CIFAR-10 Batch 1: Loss:     1.7854 Validation accuracy: 0.429600\n",
            "Epoch  7, CIFAR-10 Batch 1: Loss:     1.7298 Validation accuracy: 0.447600\n",
            "Epoch  8, CIFAR-10 Batch 1: Loss:     1.6650 Validation accuracy: 0.451200\n",
            "Epoch  9, CIFAR-10 Batch 1: Loss:     1.6697 Validation accuracy: 0.467400\n",
            "Epoch 10, CIFAR-10 Batch 1: Loss:     1.6060 Validation accuracy: 0.467200\n",
            "Epoch 11, CIFAR-10 Batch 1: Loss:     1.5784 Validation accuracy: 0.471000\n",
            "Epoch 12, CIFAR-10 Batch 1: Loss:     1.5246 Validation accuracy: 0.479000\n",
            "Epoch 13, CIFAR-10 Batch 1: Loss:     1.4941 Validation accuracy: 0.488000\n",
            "Epoch 14, CIFAR-10 Batch 1: Loss:     1.5200 Validation accuracy: 0.495200\n",
            "Epoch 15, CIFAR-10 Batch 1: Loss:     1.4476 Validation accuracy: 0.502200\n",
            "Epoch 16, CIFAR-10 Batch 1: Loss:     1.3994 Validation accuracy: 0.503800\n",
            "Epoch 17, CIFAR-10 Batch 1: Loss:     1.3943 Validation accuracy: 0.513000\n",
            "Epoch 18, CIFAR-10 Batch 1: Loss:     1.3883 Validation accuracy: 0.508000\n",
            "Epoch 19, CIFAR-10 Batch 1: Loss:     1.3476 Validation accuracy: 0.513400\n",
            "Epoch 20, CIFAR-10 Batch 1: Loss:     1.3084 Validation accuracy: 0.516200\n",
            "Epoch 21, CIFAR-10 Batch 1: Loss:     1.2738 Validation accuracy: 0.521200\n",
            "Epoch 22, CIFAR-10 Batch 1: Loss:     1.2938 Validation accuracy: 0.518000\n",
            "Epoch 23, CIFAR-10 Batch 1: Loss:     1.2727 Validation accuracy: 0.519000\n",
            "Epoch 24, CIFAR-10 Batch 1: Loss:     1.2318 Validation accuracy: 0.511000\n",
            "Epoch 25, CIFAR-10 Batch 1: Loss:     1.2376 Validation accuracy: 0.527600\n",
            "Epoch 26, CIFAR-10 Batch 1: Loss:     1.2041 Validation accuracy: 0.527400\n",
            "Epoch 27, CIFAR-10 Batch 1: Loss:     1.1874 Validation accuracy: 0.529000\n",
            "Epoch 28, CIFAR-10 Batch 1: Loss:     1.1901 Validation accuracy: 0.528600\n",
            "Epoch 29, CIFAR-10 Batch 1: Loss:     1.1731 Validation accuracy: 0.536200\n",
            "Epoch 30, CIFAR-10 Batch 1: Loss:     1.1658 Validation accuracy: 0.532400\n",
            "Epoch 31, CIFAR-10 Batch 1: Loss:     1.1281 Validation accuracy: 0.540400\n",
            "Epoch 32, CIFAR-10 Batch 1: Loss:     1.1353 Validation accuracy: 0.533000\n",
            "Epoch 33, CIFAR-10 Batch 1: Loss:     1.0975 Validation accuracy: 0.538400\n",
            "Epoch 34, CIFAR-10 Batch 1: Loss:     1.1005 Validation accuracy: 0.536400\n",
            "Epoch 35, CIFAR-10 Batch 1: Loss:     1.0663 Validation accuracy: 0.538200\n",
            "Epoch 36, CIFAR-10 Batch 1: Loss:     1.0128 Validation accuracy: 0.540000\n",
            "Epoch 37, CIFAR-10 Batch 1: Loss:     1.0177 Validation accuracy: 0.538600\n",
            "Epoch 38, CIFAR-10 Batch 1: Loss:     1.0166 Validation accuracy: 0.540600\n",
            "Epoch 39, CIFAR-10 Batch 1: Loss:     0.9904 Validation accuracy: 0.547800\n",
            "Epoch 40, CIFAR-10 Batch 1: Loss:     0.9600 Validation accuracy: 0.545800\n",
            "Epoch 41, CIFAR-10 Batch 1: Loss:     0.9975 Validation accuracy: 0.540200\n",
            "Epoch 42, CIFAR-10 Batch 1: Loss:     0.9648 Validation accuracy: 0.551400\n",
            "Epoch 43, CIFAR-10 Batch 1: Loss:     0.9563 Validation accuracy: 0.545600\n",
            "Epoch 44, CIFAR-10 Batch 1: Loss:     0.9393 Validation accuracy: 0.541600\n",
            "Epoch 45, CIFAR-10 Batch 1: Loss:     0.9162 Validation accuracy: 0.541600\n",
            "Epoch 46, CIFAR-10 Batch 1: Loss:     0.9441 Validation accuracy: 0.551000\n",
            "Epoch 47, CIFAR-10 Batch 1: Loss:     0.9312 Validation accuracy: 0.546200\n",
            "Epoch 48, CIFAR-10 Batch 1: Loss:     0.8566 Validation accuracy: 0.542200\n",
            "Epoch 49, CIFAR-10 Batch 1: Loss:     0.8691 Validation accuracy: 0.551800\n",
            "Epoch 50, CIFAR-10 Batch 1: Loss:     0.9016 Validation accuracy: 0.545800\n",
            "Epoch 51, CIFAR-10 Batch 1: Loss:     0.8878 Validation accuracy: 0.551800\n",
            "Epoch 52, CIFAR-10 Batch 1: Loss:     0.8520 Validation accuracy: 0.542400\n",
            "Epoch 53, CIFAR-10 Batch 1: Loss:     0.8492 Validation accuracy: 0.548600\n",
            "Epoch 54, CIFAR-10 Batch 1: Loss:     0.8201 Validation accuracy: 0.546800\n",
            "Epoch 55, CIFAR-10 Batch 1: Loss:     0.8459 Validation accuracy: 0.556600\n",
            "Epoch 56, CIFAR-10 Batch 1: Loss:     0.8375 Validation accuracy: 0.547800\n",
            "Epoch 57, CIFAR-10 Batch 1: Loss:     0.8139 Validation accuracy: 0.545000\n",
            "Epoch 58, CIFAR-10 Batch 1: Loss:     0.7773 Validation accuracy: 0.547400\n",
            "Epoch 59, CIFAR-10 Batch 1: Loss:     0.7990 Validation accuracy: 0.552400\n",
            "Epoch 60, CIFAR-10 Batch 1: Loss:     0.7730 Validation accuracy: 0.552000\n",
            "Epoch 61, CIFAR-10 Batch 1: Loss:     0.7465 Validation accuracy: 0.550600\n",
            "Epoch 62, CIFAR-10 Batch 1: Loss:     0.7475 Validation accuracy: 0.550800\n",
            "Epoch 63, CIFAR-10 Batch 1: Loss:     0.6811 Validation accuracy: 0.544400\n",
            "Epoch 64, CIFAR-10 Batch 1: Loss:     0.6878 Validation accuracy: 0.548000\n",
            "Epoch 65, CIFAR-10 Batch 1: Loss:     0.6992 Validation accuracy: 0.545800\n",
            "Epoch 66, CIFAR-10 Batch 1: Loss:     0.6745 Validation accuracy: 0.541000\n",
            "Epoch 67, CIFAR-10 Batch 1: Loss:     0.6525 Validation accuracy: 0.543800\n",
            "Epoch 68, CIFAR-10 Batch 1: Loss:     0.6656 Validation accuracy: 0.544200\n",
            "Epoch 69, CIFAR-10 Batch 1: Loss:     0.6339 Validation accuracy: 0.550800\n",
            "Epoch 70, CIFAR-10 Batch 1: Loss:     0.6307 Validation accuracy: 0.552400\n",
            "Epoch 71, CIFAR-10 Batch 1: Loss:     0.6159 Validation accuracy: 0.547200\n",
            "Epoch 72, CIFAR-10 Batch 1: Loss:     0.5843 Validation accuracy: 0.550200\n",
            "Epoch 73, CIFAR-10 Batch 1: Loss:     0.6182 Validation accuracy: 0.549200\n",
            "Epoch 74, CIFAR-10 Batch 1: Loss:     0.5981 Validation accuracy: 0.552200\n",
            "Epoch 75, CIFAR-10 Batch 1: Loss:     0.6255 Validation accuracy: 0.546000\n",
            "Epoch 76, CIFAR-10 Batch 1: Loss:     0.5924 Validation accuracy: 0.553800\n",
            "Epoch 77, CIFAR-10 Batch 1: Loss:     0.5545 Validation accuracy: 0.550200\n",
            "Epoch 78, CIFAR-10 Batch 1: Loss:     0.5741 Validation accuracy: 0.554200\n",
            "Epoch 79, CIFAR-10 Batch 1: Loss:     0.5455 Validation accuracy: 0.547400\n",
            "Epoch 80, CIFAR-10 Batch 1: Loss:     0.5514 Validation accuracy: 0.547000\n",
            "Epoch 81, CIFAR-10 Batch 1: Loss:     0.5025 Validation accuracy: 0.549200\n",
            "Epoch 82, CIFAR-10 Batch 1: Loss:     0.5359 Validation accuracy: 0.552600\n",
            "Epoch 83, CIFAR-10 Batch 1: Loss:     0.5138 Validation accuracy: 0.545400\n",
            "Epoch 84, CIFAR-10 Batch 1: Loss:     0.4832 Validation accuracy: 0.554400\n",
            "Epoch 85, CIFAR-10 Batch 1: Loss:     0.4939 Validation accuracy: 0.558000\n",
            "Epoch 86, CIFAR-10 Batch 1: Loss:     0.4821 Validation accuracy: 0.550200\n",
            "Epoch 87, CIFAR-10 Batch 1: Loss:     0.4640 Validation accuracy: 0.547200\n",
            "Epoch 88, CIFAR-10 Batch 1: Loss:     0.4795 Validation accuracy: 0.546600\n",
            "Epoch 89, CIFAR-10 Batch 1: Loss:     0.4618 Validation accuracy: 0.558600\n",
            "Epoch 90, CIFAR-10 Batch 1: Loss:     0.4573 Validation accuracy: 0.544800\n",
            "Epoch 91, CIFAR-10 Batch 1: Loss:     0.4469 Validation accuracy: 0.552800\n",
            "Epoch 92, CIFAR-10 Batch 1: Loss:     0.4333 Validation accuracy: 0.550400\n",
            "Epoch 93, CIFAR-10 Batch 1: Loss:     0.4609 Validation accuracy: 0.546200\n",
            "Epoch 94, CIFAR-10 Batch 1: Loss:     0.4393 Validation accuracy: 0.548000\n",
            "Epoch 95, CIFAR-10 Batch 1: Loss:     0.4202 Validation accuracy: 0.549800\n",
            "Epoch 96, CIFAR-10 Batch 1: Loss:     0.4267 Validation accuracy: 0.550800\n",
            "Epoch 97, CIFAR-10 Batch 1: Loss:     0.4402 Validation accuracy: 0.546600\n",
            "Epoch 98, CIFAR-10 Batch 1: Loss:     0.4354 Validation accuracy: 0.544200\n",
            "Epoch 99, CIFAR-10 Batch 1: Loss:     0.3784 Validation accuracy: 0.547200\n",
            "Epoch 100, CIFAR-10 Batch 1: Loss:     0.4029 Validation accuracy: 0.549600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jqL-uV3EC1ob",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kUd50P1QC2NV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PK313RUTCchR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}